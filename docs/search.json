[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "",
    "text": "This section prepares the Python environment with all necessary libraries and configurations. We’ll import data manipulation libraries (pandas, numpy), and visualization tools (matplotlib, seaborn).\n\n\n!conda install -c conda-forge numpy pandas matplotlib seaborn requests pathlib BigQuery\n\n\n\n\n\nShow the code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport importlib.util\nfrom pathlib import Path\nimport sys\nimport os\nimport requests\nimport io\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\nTrue\n\n\n\n\n\n\n\n\n\n\nShow the code\ndef fetch_github(\n    url: str,\n    mode: str = \"private\",\n    token_env_var: str = \"GITHUB_TOKEN\"\n) -&gt; requests.Response:\n    \"\"\"\n    Fetch content from GitHub repositories.\n\n    Args:\n        url: GitHub raw URL (e.g., https://raw.githubusercontent.com/...)\n        mode: \"public\" for public repos, \"private\" for private repos requiring authentication\n        token_env_var: Name of environment variable containing GitHub token (default: GITHUB_TOKEN)\n\n    Returns:\n        requests.Response object\n\n    Raises:\n        ValueError: If token is missing for private mode or invalid mode\n        requests.HTTPError: If request fails\n    \"\"\"\n    # Validate mode\n    if mode not in [\"public\", \"private\"]:\n        raise ValueError(f\"mode must be 'public' or 'private', got '{mode}'\")\n\n    if mode == \"public\":\n        response = requests.get(url, timeout=30)\n    else:\n        token = os.getenv(token_env_var)\n        if not token:\n            raise ValueError(\n                f\"GitHub token not found in environment variable '{token_env_var}'. \"\n                f\"Check your .env file has: {token_env_var}=your_token_here\"\n            )\n\n        headers = {\n            'Authorization': f'token {token}',\n            'Accept': 'application/vnd.github.v3.raw'\n        }\n        response = requests.get(url, headers=headers, timeout=30)\n\n    response.raise_for_status()\n    return response\n\n\n\n\nShow the code\ndef calculate_categorical_shares(\n    df,\n    category_col,\n    weight_col='LINKED_WEIGHT',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition=None,\n    category_mapping=None,\n    prefix='share',\n    purpose_by_period=['HBW', 'HBO', 'NHB'],  # Only HBC and HBSch get daily\n    purpose_daily=['HBC', 'HBSch']  # NEW: Purposes that only get daily (no peak/off-peak)\n):\n    \"\"\"\n    Calculate weighted shares of categories within groups, ensuring they sum to 1.\n\n    Parameters:\n    -----------\n    df : DataFrame\n        Input dataframe\n    category_col : str\n        Column containing the categories to calculate shares for\n    weight_col : str\n        Column containing weights for each observation\n    group_cols : list\n        Columns to group by (e.g., vehicle ownership, purpose, peak/off-peak)\n    filter_condition : str or None\n        Optional pandas query string to filter data before calculation\n    category_mapping : dict or None\n        Optional mapping to rename/recode categories\n    prefix : str\n        Prefix for output column names\n    purpose_by_period : list\n        Purposes that should NOT get daily aggregates\n    purpose_daily : list\n        Purposes that ONLY get daily aggregates (no peak/off-peak breakdown)\n\n    Returns:\n    --------\n    DataFrame with shares in wide format\n    \"\"\"\n\n    # Apply filter and copy in one step\n    if filter_condition:\n        df_work = df.query(filter_condition).copy()\n    else:\n        df_work = df.copy()\n\n    # Apply category mapping if provided\n    if category_mapping:\n        df_work[category_col] = df_work[category_col].map(category_mapping)\n        # Remove unmapped values\n        df_work = df_work.dropna(subset=[category_col])\n\n    # Remove any NaN values in key columns\n    df_work = df_work.dropna(subset=[category_col, weight_col] + group_cols)\n\n    # Convert Veh_Cat3p to string format for consistency\n    df_work['Veh_Cat3p'] = df_work['Veh_Cat3p'].astype(str)\n    # Map 3 to 3+ for display\n    # df_work['Veh_Cat3p'] = df_work['Veh_Cat3p'].replace('3', '3+')\n\n    # Initialize results dictionary\n    results = {}\n\n    # Calculate weighted shares for each group combination (peak/off-peak)\n    # BUT skip purpose_daily\n    for veh in sorted(df_work['Veh_Cat3p'].unique()):\n        for purpose in sorted(df_work['Purp5_text'].unique()):\n            # Skip peak/off-peak for daily-only purposes\n            if purpose in purpose_daily:\n                continue\n\n            for peak in sorted(df_work['PK_OK'].unique()):\n                subset = df_work.query(\n                    f\"Veh_Cat3p == '{veh}' & Purp5_text == '{purpose}' & PK_OK == '{peak}'\"\n                )\n\n                if len(subset) &gt; 0:\n                    # Calculate weighted counts by category\n                    weighted_counts = subset.groupby(category_col)[weight_col].sum()\n                    total_weight = subset[weight_col].sum()\n\n                    for cat, weighted_count in weighted_counts.items():\n                        var_name = f\"{prefix}_{cat}_{veh}veh\"\n                        if var_name not in results:\n                            results[var_name] = {}\n                        results[var_name][(purpose, peak)] = weighted_count / total_weight\n\n    # Calculate \"_all\" aggregates for peak/off-peak (excluding daily-only purposes)\n    for purpose in sorted(df_work['Purp5_text'].unique()):\n        # Skip peak/off-peak for daily-only purposes\n        if purpose in purpose_daily:\n            continue\n\n        for peak in sorted(df_work['PK_OK'].unique()):\n            subset = df_work.query(f\"Purp5_text == '{purpose}' & PK_OK == '{peak}'\")\n\n            if len(subset) &gt; 0:\n                weighted_counts = subset.groupby(category_col)[weight_col].sum()\n                total_weight = subset[weight_col].sum()\n\n                for cat, weighted_count in weighted_counts.items():\n                    var_name = f\"{prefix}_{cat}_all\"\n                    if var_name not in results:\n                        results[var_name] = {}\n                    results[var_name][(purpose, peak)] = weighted_count / total_weight\n\n    # Calculate daily aggregates for specified purposes only\n    daily_purposes = [p for p in df_work['Purp5_text'].unique()\n                     if p not in purpose_by_period]\n\n    for purpose in daily_purposes:\n        subset = df_work.query(f\"Purp5_text == '{purpose}'\")\n\n        if len(subset) &gt; 0:\n            # For each vehicle category\n            for veh in sorted(df_work['Veh_Cat3p'].unique()):\n                veh_subset = subset.query(f\"Veh_Cat3p == '{veh}'\")\n                if len(veh_subset) &gt; 0:\n                    weighted_counts = veh_subset.groupby(category_col)[weight_col].sum()\n                    total_weight = veh_subset[weight_col].sum()\n\n                    for cat, weighted_count in weighted_counts.items():\n                        var_name = f\"{prefix}_{cat}_{veh}veh\"\n                        if var_name not in results:\n                            results[var_name] = {}\n                        results[var_name][(purpose, 'Daily')] = weighted_count / total_weight\n\n            # For \"all\" vehicle categories\n            weighted_counts = subset.groupby(category_col)[weight_col].sum()\n            total_weight = subset[weight_col].sum()\n\n            for cat, weighted_count in weighted_counts.items():\n                var_name = f\"{prefix}_{cat}_all\"\n                if var_name not in results:\n                    results[var_name] = {}\n                results[var_name][(purpose, 'Daily')] = weighted_count / total_weight\n\n    # Convert to DataFrame\n    df_result = pd.DataFrame(results).T\n    df_result.columns = pd.MultiIndex.from_tuples(df_result.columns)\n    df_result = df_result.fillna(0)\n\n    # Sort index\n    df_result = df_result.sort_index()\n\n    return df_result\n\n\n\n\nShow the code\n# Verify categorical shares sum to 1.0000\ndef verify_shares(df_shares, tolerance=0.01):\n    \"\"\"\n    Verify that shares sum to approximately 1 within each vehicle category group.\n\n    Now that we have separate rows for each vehicle ownership category (0veh, 1veh, 2veh, 3+veh, all),\n    we need to verify that shares sum to 1 within each vehicle category separately.\n    \"\"\"\n    print(\"=== Verifying Share Sums ===\\n\")\n\n    # Extract vehicle categories from index\n    # Assuming format: calib_share_{category}_{veh_category}\n    vehicle_categories = df_shares.index.str.extract(r'_(\\d\\+?veh|all)$')[0].unique()\n\n    print(f\"Vehicle categories found: {sorted(vehicle_categories)}\\n\")\n\n    all_good = True\n    issues = []\n\n    # Check each vehicle category separately\n    for veh_cat in sorted(vehicle_categories):\n        # Filter rows for this vehicle category\n        mask = df_shares.index.str.endswith(f'_{veh_cat}')\n        df_veh = df_shares[mask]\n\n        print(f\"--- Checking {veh_cat} ({len(df_veh)} categories) ---\")\n\n        # Check sums for each column within this vehicle category\n        veh_issues = []\n        for col in df_veh.columns:\n            col_sum = df_veh[col].sum()\n\n            if abs(col_sum - 1.0) &gt; tolerance:\n                all_good = False\n                veh_issues.append((col, col_sum))\n\n        if not veh_issues:\n            print(f\"  ✅ All shares sum to 1.0 for {veh_cat}\")\n        else:\n            print(f\"  ⚠️  {len(veh_issues)} columns don't sum to 1.0 for {veh_cat}:\")\n            for col, sum_val in veh_issues[:5]:  # Show first 5\n                print(f\"     {col}: {sum_val:.4f}\")\n            if len(veh_issues) &gt; 5:\n                print(f\"     ... and {len(veh_issues) - 5} more\")\n            issues.extend([(veh_cat, col, sum_val) for col, sum_val in veh_issues])\n        print()\n\n    print(f\"{'='*60}\")\n    if all_good:\n        print(\"✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\")\n    else:\n        print(f\"⚠️  WARNING: {len(issues)} total column/vehicle combinations don't sum to 1.0\")\n\n    print(f\"\\nTotal columns: {len(df_shares.columns)}\")\n    print(f\"Total vehicle categories: {len(vehicle_categories)}\")\n    print(f\"Total combinations: {len(df_shares.columns) * len(vehicle_categories)}\")\n\n    # Return sums by vehicle category\n    return {veh_cat: df_shares[df_shares.index.str.endswith(f'_{veh_cat}')].sum(axis=0)\n            for veh_cat in sorted(vehicle_categories)}\n\n\n\n\n\n\n\nShow the code\n# # Import global TDM functions from remote 'Resource' repo\n\n# Fetch and import BigQuery module\nresponse = fetch_github(\n    'https://raw.githubusercontent.com/WFRCAnalytics/Resources/refs/heads/master/2-Python/global-functions/BigQuery.py',\n    mode=\"public\"\n)\n\nBigQuery = importlib.util.module_from_spec(importlib.util.spec_from_loader('BigQuery', loader=None))\nexec(response.text, BigQuery.__dict__)\n\n# Initiatlize BigQuery Client\nclient = BigQuery.getBigQueryClient_Confidential2023UtahHTS()\n\n\npukar.bhandari\nC:/Users/Pukar.Bhandari/.private/confidential-2023-utah-hts-5fd7ddd219a7.json"
  },
  {
    "objectID": "index.html#install-libraries",
    "href": "index.html#install-libraries",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "",
    "text": "!conda install -c conda-forge numpy pandas matplotlib seaborn requests pathlib BigQuery"
  },
  {
    "objectID": "index.html#import-libraries",
    "href": "index.html#import-libraries",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "",
    "text": "Show the code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport importlib.util\nfrom pathlib import Path\nimport sys\nimport os\nimport requests\nimport io\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\nTrue"
  },
  {
    "objectID": "index.html#helper-functions",
    "href": "index.html#helper-functions",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "",
    "text": "Show the code\ndef fetch_github(\n    url: str,\n    mode: str = \"private\",\n    token_env_var: str = \"GITHUB_TOKEN\"\n) -&gt; requests.Response:\n    \"\"\"\n    Fetch content from GitHub repositories.\n\n    Args:\n        url: GitHub raw URL (e.g., https://raw.githubusercontent.com/...)\n        mode: \"public\" for public repos, \"private\" for private repos requiring authentication\n        token_env_var: Name of environment variable containing GitHub token (default: GITHUB_TOKEN)\n\n    Returns:\n        requests.Response object\n\n    Raises:\n        ValueError: If token is missing for private mode or invalid mode\n        requests.HTTPError: If request fails\n    \"\"\"\n    # Validate mode\n    if mode not in [\"public\", \"private\"]:\n        raise ValueError(f\"mode must be 'public' or 'private', got '{mode}'\")\n\n    if mode == \"public\":\n        response = requests.get(url, timeout=30)\n    else:\n        token = os.getenv(token_env_var)\n        if not token:\n            raise ValueError(\n                f\"GitHub token not found in environment variable '{token_env_var}'. \"\n                f\"Check your .env file has: {token_env_var}=your_token_here\"\n            )\n\n        headers = {\n            'Authorization': f'token {token}',\n            'Accept': 'application/vnd.github.v3.raw'\n        }\n        response = requests.get(url, headers=headers, timeout=30)\n\n    response.raise_for_status()\n    return response\n\n\n\n\nShow the code\ndef calculate_categorical_shares(\n    df,\n    category_col,\n    weight_col='LINKED_WEIGHT',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition=None,\n    category_mapping=None,\n    prefix='share',\n    purpose_by_period=['HBW', 'HBO', 'NHB'],  # Only HBC and HBSch get daily\n    purpose_daily=['HBC', 'HBSch']  # NEW: Purposes that only get daily (no peak/off-peak)\n):\n    \"\"\"\n    Calculate weighted shares of categories within groups, ensuring they sum to 1.\n\n    Parameters:\n    -----------\n    df : DataFrame\n        Input dataframe\n    category_col : str\n        Column containing the categories to calculate shares for\n    weight_col : str\n        Column containing weights for each observation\n    group_cols : list\n        Columns to group by (e.g., vehicle ownership, purpose, peak/off-peak)\n    filter_condition : str or None\n        Optional pandas query string to filter data before calculation\n    category_mapping : dict or None\n        Optional mapping to rename/recode categories\n    prefix : str\n        Prefix for output column names\n    purpose_by_period : list\n        Purposes that should NOT get daily aggregates\n    purpose_daily : list\n        Purposes that ONLY get daily aggregates (no peak/off-peak breakdown)\n\n    Returns:\n    --------\n    DataFrame with shares in wide format\n    \"\"\"\n\n    # Apply filter and copy in one step\n    if filter_condition:\n        df_work = df.query(filter_condition).copy()\n    else:\n        df_work = df.copy()\n\n    # Apply category mapping if provided\n    if category_mapping:\n        df_work[category_col] = df_work[category_col].map(category_mapping)\n        # Remove unmapped values\n        df_work = df_work.dropna(subset=[category_col])\n\n    # Remove any NaN values in key columns\n    df_work = df_work.dropna(subset=[category_col, weight_col] + group_cols)\n\n    # Convert Veh_Cat3p to string format for consistency\n    df_work['Veh_Cat3p'] = df_work['Veh_Cat3p'].astype(str)\n    # Map 3 to 3+ for display\n    # df_work['Veh_Cat3p'] = df_work['Veh_Cat3p'].replace('3', '3+')\n\n    # Initialize results dictionary\n    results = {}\n\n    # Calculate weighted shares for each group combination (peak/off-peak)\n    # BUT skip purpose_daily\n    for veh in sorted(df_work['Veh_Cat3p'].unique()):\n        for purpose in sorted(df_work['Purp5_text'].unique()):\n            # Skip peak/off-peak for daily-only purposes\n            if purpose in purpose_daily:\n                continue\n\n            for peak in sorted(df_work['PK_OK'].unique()):\n                subset = df_work.query(\n                    f\"Veh_Cat3p == '{veh}' & Purp5_text == '{purpose}' & PK_OK == '{peak}'\"\n                )\n\n                if len(subset) &gt; 0:\n                    # Calculate weighted counts by category\n                    weighted_counts = subset.groupby(category_col)[weight_col].sum()\n                    total_weight = subset[weight_col].sum()\n\n                    for cat, weighted_count in weighted_counts.items():\n                        var_name = f\"{prefix}_{cat}_{veh}veh\"\n                        if var_name not in results:\n                            results[var_name] = {}\n                        results[var_name][(purpose, peak)] = weighted_count / total_weight\n\n    # Calculate \"_all\" aggregates for peak/off-peak (excluding daily-only purposes)\n    for purpose in sorted(df_work['Purp5_text'].unique()):\n        # Skip peak/off-peak for daily-only purposes\n        if purpose in purpose_daily:\n            continue\n\n        for peak in sorted(df_work['PK_OK'].unique()):\n            subset = df_work.query(f\"Purp5_text == '{purpose}' & PK_OK == '{peak}'\")\n\n            if len(subset) &gt; 0:\n                weighted_counts = subset.groupby(category_col)[weight_col].sum()\n                total_weight = subset[weight_col].sum()\n\n                for cat, weighted_count in weighted_counts.items():\n                    var_name = f\"{prefix}_{cat}_all\"\n                    if var_name not in results:\n                        results[var_name] = {}\n                    results[var_name][(purpose, peak)] = weighted_count / total_weight\n\n    # Calculate daily aggregates for specified purposes only\n    daily_purposes = [p for p in df_work['Purp5_text'].unique()\n                     if p not in purpose_by_period]\n\n    for purpose in daily_purposes:\n        subset = df_work.query(f\"Purp5_text == '{purpose}'\")\n\n        if len(subset) &gt; 0:\n            # For each vehicle category\n            for veh in sorted(df_work['Veh_Cat3p'].unique()):\n                veh_subset = subset.query(f\"Veh_Cat3p == '{veh}'\")\n                if len(veh_subset) &gt; 0:\n                    weighted_counts = veh_subset.groupby(category_col)[weight_col].sum()\n                    total_weight = veh_subset[weight_col].sum()\n\n                    for cat, weighted_count in weighted_counts.items():\n                        var_name = f\"{prefix}_{cat}_{veh}veh\"\n                        if var_name not in results:\n                            results[var_name] = {}\n                        results[var_name][(purpose, 'Daily')] = weighted_count / total_weight\n\n            # For \"all\" vehicle categories\n            weighted_counts = subset.groupby(category_col)[weight_col].sum()\n            total_weight = subset[weight_col].sum()\n\n            for cat, weighted_count in weighted_counts.items():\n                var_name = f\"{prefix}_{cat}_all\"\n                if var_name not in results:\n                    results[var_name] = {}\n                results[var_name][(purpose, 'Daily')] = weighted_count / total_weight\n\n    # Convert to DataFrame\n    df_result = pd.DataFrame(results).T\n    df_result.columns = pd.MultiIndex.from_tuples(df_result.columns)\n    df_result = df_result.fillna(0)\n\n    # Sort index\n    df_result = df_result.sort_index()\n\n    return df_result\n\n\n\n\nShow the code\n# Verify categorical shares sum to 1.0000\ndef verify_shares(df_shares, tolerance=0.01):\n    \"\"\"\n    Verify that shares sum to approximately 1 within each vehicle category group.\n\n    Now that we have separate rows for each vehicle ownership category (0veh, 1veh, 2veh, 3+veh, all),\n    we need to verify that shares sum to 1 within each vehicle category separately.\n    \"\"\"\n    print(\"=== Verifying Share Sums ===\\n\")\n\n    # Extract vehicle categories from index\n    # Assuming format: calib_share_{category}_{veh_category}\n    vehicle_categories = df_shares.index.str.extract(r'_(\\d\\+?veh|all)$')[0].unique()\n\n    print(f\"Vehicle categories found: {sorted(vehicle_categories)}\\n\")\n\n    all_good = True\n    issues = []\n\n    # Check each vehicle category separately\n    for veh_cat in sorted(vehicle_categories):\n        # Filter rows for this vehicle category\n        mask = df_shares.index.str.endswith(f'_{veh_cat}')\n        df_veh = df_shares[mask]\n\n        print(f\"--- Checking {veh_cat} ({len(df_veh)} categories) ---\")\n\n        # Check sums for each column within this vehicle category\n        veh_issues = []\n        for col in df_veh.columns:\n            col_sum = df_veh[col].sum()\n\n            if abs(col_sum - 1.0) &gt; tolerance:\n                all_good = False\n                veh_issues.append((col, col_sum))\n\n        if not veh_issues:\n            print(f\"  ✅ All shares sum to 1.0 for {veh_cat}\")\n        else:\n            print(f\"  ⚠️  {len(veh_issues)} columns don't sum to 1.0 for {veh_cat}:\")\n            for col, sum_val in veh_issues[:5]:  # Show first 5\n                print(f\"     {col}: {sum_val:.4f}\")\n            if len(veh_issues) &gt; 5:\n                print(f\"     ... and {len(veh_issues) - 5} more\")\n            issues.extend([(veh_cat, col, sum_val) for col, sum_val in veh_issues])\n        print()\n\n    print(f\"{'='*60}\")\n    if all_good:\n        print(\"✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\")\n    else:\n        print(f\"⚠️  WARNING: {len(issues)} total column/vehicle combinations don't sum to 1.0\")\n\n    print(f\"\\nTotal columns: {len(df_shares.columns)}\")\n    print(f\"Total vehicle categories: {len(vehicle_categories)}\")\n    print(f\"Total combinations: {len(df_shares.columns) * len(vehicle_categories)}\")\n\n    # Return sums by vehicle category\n    return {veh_cat: df_shares[df_shares.index.str.endswith(f'_{veh_cat}')].sum(axis=0)\n            for veh_cat in sorted(vehicle_categories)}"
  },
  {
    "objectID": "index.html#setup-bigquery",
    "href": "index.html#setup-bigquery",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "",
    "text": "Show the code\n# # Import global TDM functions from remote 'Resource' repo\n\n# Fetch and import BigQuery module\nresponse = fetch_github(\n    'https://raw.githubusercontent.com/WFRCAnalytics/Resources/refs/heads/master/2-Python/global-functions/BigQuery.py',\n    mode=\"public\"\n)\n\nBigQuery = importlib.util.module_from_spec(importlib.util.spec_from_loader('BigQuery', loader=None))\nexec(response.text, BigQuery.__dict__)\n\n# Initiatlize BigQuery Client\nclient = BigQuery.getBigQueryClient_Confidential2023UtahHTS()\n\n\npukar.bhandari\nC:/Users/Pukar.Bhandari/.private/confidential-2023-utah-hts-5fd7ddd219a7.json"
  },
  {
    "objectID": "index.html#uta-on-board-survey",
    "href": "index.html#uta-on-board-survey",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "2.1 UTA On-Board Survey",
    "text": "2.1 UTA On-Board Survey\n\n\nShow the code\n# Read Linked UTA On-Board Survey Data directly from GitHub repo\nresponse = fetch_github(\n    \"https://raw.githubusercontent.com/WFRCAnalytics/DATA-OBS-Prep-For-TDM/refs/heads/main/_output/UTA_OBS_2024_Linked.csv\",\n    mode = \"private\"\n)\n\ndf_obs_linked = pd.read_csv(io.StringIO(response.text))\ndf_obs_linked\n\n\nC:\\Users\\Pukar.Bhandari\\AppData\\Local\\Temp\\ipykernel_34668\\4156658631.py:7: DtypeWarning:\n\nColumns (8,24,32,37,54,132,137,174) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\n\n\n\n\n\n\nID\nDATE_COMPLETED\nDATE_TYPE\nROUTE_DIRECTION_Code\nROUTE_DIRECTION\nROUTE_DIRECTION_Other\nHOME_ADDRESS_CITY\nHOME_ADDRESS_STATE\nHOME_ADDRESS_ZIP\nHOME_ADDRESS_LAT\n...\np_Stop_lat\np_Stop_lon\na_Stop_lat\na_Stop_lon\np_Stop_N\na_Stop_N\naccess_dist\naccess_time\negress_dist\negress_time\n\n\n\n\n0\n5948\n2/27/2024\nWeekday\nUTA_1_2_00\n2 200 SOUTH - TO U HOSPITAL\nNaN\nClearfield\nUT\n84015\n41.119565\n...\n41.118979\n-112.025922\n40.769221\n-111.898663\n27702.0\n25493.0\n0.37\n8.79\n0.68\n16.27\n\n\n1\n6067\n2/27/2024\nWeekday\nUTA_1_47_00\n47 4700 SOUTH - TO W VALLEY CTL\nNaN\nWest Valley City\nUT\n84119\n40.689590\n...\n40.689384\n-111.967476\n40.660941\n-111.899443\n23195.0\n23685.0\n0.56\n13.53\n0.24\n5.70\n\n\n2\n6069\n3/16/2024\nSaturday\nUTA_1_750_01\nFRONTRUNNER 750 - SOUTHBOUND\nNaN\nOgden\nUT\n84401\n41.186697\n...\n41.188757\n-112.039378\n40.784356\n-111.982117\n10042.0\n15093.0\n1.15\n2.76\n0.20\n4.89\n\n\n3\n6073\n2/28/2024\nWeekday\nUTA_1_750_01\nFRONTRUNNER 750 - SOUTHBOUND\nNaN\nOgden\nUT\n84401\n41.236749\n...\n41.188757\n-112.039378\n40.659758\n-111.896432\n10042.0\n10016.0\n4.17\n8.22\n1.37\n3.29\n\n\n4\n6077\n2/28/2024\nWeekday\nUTA_1_47_00\n47 4700 SOUTH - TO W VALLEY CTL\nNaN\nWest Valley City\nUT\n84119\n40.669687\n...\n40.667711\n-111.961123\n40.681907\n-112.024041\n22922.0\n22421.0\n0.25\n6.00\n0.49\n11.88\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13790\n30339\n4/26/2024\nWeekday\nUTA_1_704_01\nTRAX GREEN LINE 704 - TO AIRPORT\nNaN\nSalt Lake City\nUT\n84116\n40.772420\n...\n40.771536\n-111.945736\n40.771502\n-111.914486\n15101.0\n15122.0\n0.31\n7.53\n0.17\n4.07\n\n\n13791\n30340\n4/26/2024\nWeekday\nUTA_1_704_00\nTRAX GREEN LINE 704 - TO WEST VALLEY\nNaN\nSalt Lake City\nUT\n84116\n40.771361\n...\n40.771505\n-111.915361\n40.750058\n-111.896818\n15122.0\n15109.0\n0.46\n11.00\n1.21\n29.10\n\n\n13792\n30341\n4/26/2024\nWeekday\nUTA_1_704_00\nTRAX GREEN LINE 704 - TO WEST VALLEY\nNaN\nSalt Lake City\nUT\n84116\n40.773232\n...\n40.771505\n-111.915361\n40.725345\n-111.877499\n15122.0\n24968.0\n0.17\n4.07\n0.86\n20.68\n\n\n13793\n1000002\n2/29/2024\nWeekday\nUTA_1_701_00\nTRAX BLUE LINE 701 - TO DRAPER\nNaN\nSalt Lake City\nUT\n84111\n40.751607\n...\n40.755113\n-111.891095\n40.674859\n-111.943134\n15123.0\n23342.0\n0.33\n7.95\n0.29\n7.02\n\n\n13794\n1000004\n2/29/2024\nWeekday\nUTA_1_701_00\nTRAX BLUE LINE 701 - TO DRAPER\nNaN\nSalt Lake City\nUT\n84109\n40.722068\n...\n40.725878\n-111.830935\n40.525496\n-111.858805\n25663.0\n15041.0\n0.79\n18.85\n0.19\n4.44\n\n\n\n\n13795 rows × 303 columns"
  },
  {
    "objectID": "index.html#household-travel-survey",
    "href": "index.html#household-travel-survey",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "2.2 Household Travel Survey",
    "text": "2.2 Household Travel Survey\n\n\nShow the code\n# Load Linked Trips data from 2023 Household Travel Survey\ndf_hts_linked = client.query(\n    \"SELECT hh_id, PURP7_t, depart_per, model_trip_mode_WFv10, trip_weight FROM \" + 'wfrc-modeling-data.prd_tdm_hts_2023.trip_linked'\n).to_dataframe()\n\ndf_hts_linked\n\n\n\n\n\n\n\n\n\nhh_id\nPURP7_t\ndepart_per\nmodel_trip_mode_WFv10\ntrip_weight\n\n\n\n\n0\n23041058\nHBC\nAM\nauto_occ2\n38.667618\n\n\n1\n23089619\nHBC\nAM\nauto_sov\n249.670620\n\n\n2\n23004082\nHBOth\nAM\nauto_sov\n0.335684\n\n\n3\n23004082\nHBOth\nAM\nauto_occ2\n0.335684\n\n\n4\n23006036\nHBOth\nAM\ndrive-to-transit\n192.779770\n\n\n...\n...\n...\n...\n...\n...\n\n\n769\n23468106\nNHBW\nPM\nauto_sov\n29.555339\n\n\n770\n23481219\nNHBW\nPM\nauto_sov\n0.000000\n\n\n771\n23485070\nNHBW\nPM\nauto_sov\n40.853892\n\n\n772\n23485704\nNHBW\nPM\nbike\n21.135348\n\n\n773\n23494181\nNHBW\nPM\nauto_occ2\n9.263474\n\n\n\n\n232451 rows × 5 columns\n\n\n\n\n\nShow the code\n# Load Household data from 2023 Household Travel Survey\ndf_hts_hh = client.query(\n    \"SELECT hh_id, num_vehicles_4cat FROM \" + 'wfrc-modeling-data.prd_tdm_hts_2023.hh'\n).to_dataframe()\n\ndf_hts_hh\n\n\n\n\n\n\n\n\n\nhh_id\nnum_vehicles_4cat\n\n\n\n\n0\n23472690\n3\n\n\n1\n23307416\n3\n\n\n2\n23317145\n2\n\n\n3\n23321176\n2\n\n\n4\n23345703\n2\n\n\n...\n...\n...\n\n\n11178\n23165031\n1\n\n\n11179\n23046966\n1\n\n\n11180\n23043011\n1\n\n\n11181\n23376736\n1\n\n\n11182\n23085912\n3\n\n\n\n\n11183 rows × 2 columns"
  },
  {
    "objectID": "index.html#on-board-survey",
    "href": "index.html#on-board-survey",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "4.1 On-Board Survey",
    "text": "4.1 On-Board Survey\n\n\nShow the code\ndf_obs_linked[[\n    \"Linked_Mode_txt\", # Linked Mode: MT = MicroTransit (dont need), LCL = local bus, COR = Core Bus, EXP = Express Bus, LRT = Light Rail Transit (TRAX), CRT = Commuter Rail Transit (FrontRunner), BRT = Bus Rapid Transit (OVX, UVX)\n    \"Purp5_text\", # Trip Purpose: HBW = Home-based Work, HBO = Home-based Other, HBC = Home-based College, NHB = Non-home based, HBSch = Home-based School\n    \"PK_OK\", # Peak vs OffPeak\n    \"Veh_Cat3p\", # Vehicle Ownership: 0 = 0 Vehicle Household, 1 = 1 Vehicle Household, 2 = 2 Vehicle Household, 3 = 3+ Vehicle Household\n    \"Mode_Fin\", # Current Mode: 1 = MT = MicroTransit (Dont need),  4 = LCL = local bus, 5 = COR = Core Bus, 6 = EXP = Express Bus, 7 = LRT = Light Rail Transit (TRAX), 8 = CRT = Commuter Rail Transit, 9 = BRT = Bus Rapid Transit (OVX, UVX)\n    \"Ac_Mode_Model\", # Access Mode to Transit: Walk (Walk to Transit), Drive (Drive to Transit)\n]]"
  },
  {
    "objectID": "index.html#purpose-5-category",
    "href": "index.html#purpose-5-category",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "5.1 Purpose (5-category)",
    "text": "5.1 Purpose (5-category)\n\n\nShow the code\npurpose_mapping = {\n    'HBOth' : 'HBO',\n    'NHBNW' : 'NHB',\n    'HBW'   : 'HBW',\n    'NHBW'  : 'NHB',\n    'HBShp' : 'HBO',\n    'HBSch' : 'HBSch',\n    'HBC'   : 'HBC'\n}\n\ndf_hts_linked['Purp5_text'] = df_hts_linked['PURP7_t'].map(purpose_mapping)"
  },
  {
    "objectID": "index.html#vehicle-ownership",
    "href": "index.html#vehicle-ownership",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "5.2 Vehicle Ownership",
    "text": "5.2 Vehicle Ownership\n\n\nShow the code\n# Join household data to linked trips data\ndf_hts_linked = df_hts_linked.merge(\n    df_hts_hh.rename(columns={'num_vehicles_4cat': 'Veh_Cat3p'}),\n    on='hh_id',\n    how='left'  # Keep all trips, even if household data is missing\n)\n\n# Rename the vehicle ownership column to match the OBS data\ndf_hts_linked = df_hts_linked.rename(columns={'num_vehicles_4cat': 'Veh_Cat3p'})"
  },
  {
    "objectID": "index.html#peak---offpeak",
    "href": "index.html#peak---offpeak",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "5.3 Peak - Offpeak",
    "text": "5.3 Peak - Offpeak\n\n\nShow the code\ndf_hts_linked['PK_OK'] = np.where(\n    df_hts_linked[\"depart_per\"].isin([\"AM\", \"PM\"]),\n    \"PK\",\n    \"OK\"\n)"
  },
  {
    "objectID": "index.html#non-motorized-trips-walk-vs-bike",
    "href": "index.html#non-motorized-trips-walk-vs-bike",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "6.1 Non-motorized Trips: Walk vs Bike",
    "text": "6.1 Non-motorized Trips: Walk vs Bike\n\n\nShow the code\n# 2. NON-MOTORIZED TRIPS\nprint(\"\\n\" + \"=\" * 60)\nprint(\"2. NON-MOTORIZED TRIPS\")\nprint(\"=\" * 60)\n\n# non_motorized_mapping = {\n#     'walk' : 'walk',\n#     'bike' : 'bike'\n# }\n\ndf_nonmotorized_cat = calculate_categorical_shares(\n    df_hts_linked,\n    category_col='model_trip_mode_WFv10',\n    weight_col='trip_weight',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='model_trip_mode_WFv10 in [\"walk\", \"bike\"]',\n    category_mapping=None,\n    prefix='calib_share'\n)\n\nprint(\"\\nShape:\", df_nonmotorized_cat.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_nonmotorized_cat.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_nonmotorized_cat)\n\n\n\n============================================================\n2. NON-MOTORIZED TRIPS\n============================================================\n\nShape: (10, 8)\n\nFirst few rows:\n                            HBO                 HBW                 NHB  \\\n                             OK        PK        OK        PK        OK   \ncalib_share_bike_0veh  0.093370  0.081922  0.126895  0.184947  0.096749   \ncalib_share_bike_1veh  0.141585  0.107295  0.225268  0.300143  0.100676   \ncalib_share_bike_2veh  0.104966  0.139940  0.338888  0.382897  0.076727   \ncalib_share_bike_3veh  0.131393  0.033276  0.110195  0.564415  0.056874   \ncalib_share_bike_all   0.117384  0.107575  0.215958  0.377379  0.076507   \ncalib_share_walk_0veh  0.906630  0.918078  0.873105  0.815053  0.903251   \ncalib_share_walk_1veh  0.858415  0.892705  0.774732  0.699857  0.899324   \ncalib_share_walk_2veh  0.895034  0.860060  0.661112  0.617103  0.923273   \ncalib_share_walk_3veh  0.868607  0.966724  0.889805  0.435585  0.943126   \ncalib_share_walk_all   0.882616  0.892425  0.784042  0.622621  0.923493   \n\n                                    HBSch       HBC  \n                             PK     Daily     Daily  \ncalib_share_bike_0veh  0.168994  0.023156  0.007745  \ncalib_share_bike_1veh  0.110790  0.135214  0.167210  \ncalib_share_bike_2veh  0.074370  0.107164  0.101549  \ncalib_share_bike_3veh  0.076972  0.103986  0.000000  \ncalib_share_bike_all   0.088079  0.107922  0.063449  \ncalib_share_walk_0veh  0.831006  0.976844  0.992255  \ncalib_share_walk_1veh  0.889210  0.864786  0.832790  \ncalib_share_walk_2veh  0.925630  0.892836  0.898451  \ncalib_share_walk_3veh  0.923028  0.896014  1.000000  \ncalib_share_walk_all   0.911921  0.892078  0.936551  \n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (2 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBSch  Daily    1.0\n HBC    Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBSch  Daily    1.0\n HBC    Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBSch  Daily    1.0\n HBC    Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBSch  Daily    1.0\n HBC    Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBSch  Daily    1.0\n HBC    Daily    1.0\n dtype: float64}"
  },
  {
    "objectID": "index.html#motorized-trips-auto-vs-transit",
    "href": "index.html#motorized-trips-auto-vs-transit",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "6.2 Motorized Trips: Auto vs Transit",
    "text": "6.2 Motorized Trips: Auto vs Transit\n\n\nShow the code\n# 3. Motorized Trips: Auto vs Transit\nprint(\"\\n\" + \"=\" * 60)\nprint(\"3. MOTORIZED TRIPS: AUTO VS TRANSIT\")\nprint(\"=\" * 60)\n\nmotorized_mapping = {\n    'auto-sov'         : 'auto',\n    'auto_occ2'        : 'auto',\n    'auto_occ3p'       : 'auto',\n    'walk-to-transit'  : 'transit',\n    'drive-to-transit' : 'transit'\n}\n\ndf_motorized_cat = calculate_categorical_shares(\n    df_hts_linked,\n    category_col='model_trip_mode_WFv10',\n    weight_col='trip_weight',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='model_trip_mode_WFv10 in [\"auto-sov\", \"auto_occ2\", \"auto_occ3p\", \"walk-to-transit\", \"drive-to-transit\"]',\n    category_mapping=motorized_mapping,\n    prefix='calib_share'\n)\n\nprint(\"\\nShape:\", df_motorized_cat.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_motorized_cat.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_motorized_cat)\n\n\n\n============================================================\n3. MOTORIZED TRIPS: AUTO VS TRANSIT\n============================================================\n\nShape: (10, 8)\n\nFirst few rows:\n                               HBO                 HBW                 NHB  \\\n                                OK        PK        OK        PK        OK   \ncalib_share_auto_0veh     0.461486  0.699976  0.737624  0.565582  0.700697   \ncalib_share_auto_1veh     0.982298  0.966485  0.844695  0.820529  0.982598   \ncalib_share_auto_2veh     0.995405  0.993468  0.924967  0.894349  0.992702   \ncalib_share_auto_3veh     0.997980  0.998208  0.957457  0.913352  0.988281   \ncalib_share_auto_all      0.987124  0.987439  0.902172  0.872203  0.985916   \ncalib_share_transit_0veh  0.538514  0.300024  0.262376  0.434418  0.299303   \ncalib_share_transit_1veh  0.017702  0.033515  0.155305  0.179471  0.017402   \ncalib_share_transit_2veh  0.004595  0.006532  0.075033  0.105651  0.007298   \ncalib_share_transit_3veh  0.002020  0.001792  0.042543  0.086648  0.011719   \ncalib_share_transit_all   0.012876  0.012561  0.097828  0.127797  0.014084   \n\n                                         HBC     HBSch  \n                                PK     Daily     Daily  \ncalib_share_auto_0veh     0.595672  0.556326  0.383176  \ncalib_share_auto_1veh     0.983317  0.780460  0.977310  \ncalib_share_auto_2veh     0.989979  0.598645  0.989189  \ncalib_share_auto_3veh     0.989260  0.691264  0.997318  \ncalib_share_auto_all      0.985975  0.691810  0.991149  \ncalib_share_transit_0veh  0.404328  0.443674  0.616824  \ncalib_share_transit_1veh  0.016683  0.219540  0.022690  \ncalib_share_transit_2veh  0.010021  0.401355  0.010811  \ncalib_share_transit_3veh  0.010740  0.308736  0.002682  \ncalib_share_transit_all   0.014025  0.308190  0.008851  \n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (2 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64}\n\n\n\nAuto Trips: Drive Alone vs Shared Rides\n\n\nShow the code\n# 4. Auto Trips: Drive Alone vs Shared Rides\nprint(\"\\n\" + \"=\" * 60)\nprint(\"4. AUTO TRIPS: DRIVE ALONE VS SHARED RIDES\")\nprint(\"=\" * 60)\n\nauto_ride_mapping = {\n    'auto-sov'   : 'alone',\n    'auto_occ2'  : 'shared',\n    'auto_occ3p' : 'shared'\n}\n\ndf_auto_riders = calculate_categorical_shares(\n    df_hts_linked,\n    category_col='model_trip_mode_WFv10',\n    weight_col='trip_weight',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='model_trip_mode_WFv10 in [\"auto-sov\", \"auto_occ2\", \"auto_occ3p\"]',\n    category_mapping=auto_ride_mapping,\n    prefix='calib_share'\n)\n\nprint(\"\\nShape:\", df_auto_riders.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_auto_riders.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_auto_riders)\n\n\n\n============================================================\n4. AUTO TRIPS: DRIVE ALONE VS SHARED RIDES\n============================================================\n\nShape: (5, 8)\n\nFirst few rows:\n                         HBO       HBW       NHB        HBC HBSch\n                          OK   PK   OK   PK   OK   PK Daily Daily\ncalib_share_shared_0veh  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0\ncalib_share_shared_1veh  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0\ncalib_share_shared_2veh  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0\ncalib_share_shared_3veh  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0\ncalib_share_shared_all   1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0\n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (1 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (1 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (1 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (1 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (1 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64}\n\n\n\nShared Rides: 2 People vs 3+ People\n\n\nShow the code\n# 5. Shared Ride by the Number of People\nprint(\"\\n\" + \"=\" * 60)\nprint(\"5. SHARED RIDER BY NUMBER OF PEOPLE\")\nprint(\"=\" * 60)\n\nshared_ride_mapping = {\n    'auto_occ2' : 'sr2',\n    'auto_occ3p': 'sr3'\n}\n\ndf_shared_by_person = calculate_categorical_shares(\n    df_hts_linked,\n    category_col='model_trip_mode_WFv10',\n    weight_col='trip_weight',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='model_trip_mode_WFv10 in [\"auto_occ2\", \"auto_occ3p\"]',\n    category_mapping=shared_ride_mapping,\n    prefix='calib_share'\n)\n\nprint(\"\\nShape:\", df_shared_by_person.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_shared_by_person.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_shared_by_person)\n\n\n\n============================================================\n5. SHARED RIDER BY NUMBER OF PEOPLE\n============================================================\n\nShape: (10, 8)\n\nFirst few rows:\n                           HBO                 HBW                 NHB  \\\n                            OK        PK        OK        PK        OK   \ncalib_share_sr2_0veh  0.709382  0.289280  0.731697  0.857568  0.740220   \ncalib_share_sr2_1veh  0.565882  0.518618  0.726008  0.795799  0.551582   \ncalib_share_sr2_2veh  0.512200  0.461630  0.792496  0.756507  0.458916   \ncalib_share_sr2_3veh  0.574960  0.531453  0.784871  0.702538  0.517496   \ncalib_share_sr2_all   0.543836  0.493188  0.770847  0.747774  0.498240   \ncalib_share_sr3_0veh  0.290618  0.710720  0.268303  0.142432  0.259780   \ncalib_share_sr3_1veh  0.434118  0.481382  0.273992  0.204201  0.448418   \ncalib_share_sr3_2veh  0.487800  0.538370  0.207504  0.243493  0.541084   \ncalib_share_sr3_3veh  0.425040  0.468547  0.215129  0.297462  0.482504   \ncalib_share_sr3_all   0.456164  0.506812  0.229153  0.252226  0.501760   \n\n                                     HBC     HBSch  \n                            PK     Daily     Daily  \ncalib_share_sr2_0veh  0.785824  0.950890  0.000000  \ncalib_share_sr2_1veh  0.509631  0.707841  0.308240  \ncalib_share_sr2_2veh  0.458682  0.968752  0.298725  \ncalib_share_sr2_3veh  0.493538  0.582443  0.437045  \ncalib_share_sr2_all   0.480974  0.733967  0.360179  \ncalib_share_sr3_0veh  0.214176  0.049110  1.000000  \ncalib_share_sr3_1veh  0.490369  0.292159  0.691760  \ncalib_share_sr3_2veh  0.541318  0.031248  0.701275  \ncalib_share_sr3_3veh  0.506462  0.417557  0.562955  \ncalib_share_sr3_all   0.519026  0.266033  0.639821  \n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (2 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64}\n\n\n\n\n\nTransit Trips: By Service and By Access Mode\n\nBy Service Type\n\n\nShow the code\n# 6. Transit by Service Type (within linked transit trips)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"6. TRANSIT BY SERVICE TYPE\")\nprint(\"=\" * 60)\n\nservice_mapping = {\n    'LCL': 'local',\n    'COR': 'core',\n    'EXP': 'express',\n    'LRT': 'lrt',\n    'CRT': 'crt',\n    'BRT': 'brt'\n}\n\ndf_transit_by_service = calculate_categorical_shares(\n    df_obs_linked,\n    category_col='Linked_Mode_txt',\n    weight_col='LINKED_WEIGHT',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='Linked_Mode_txt != \"MT\"',\n    category_mapping=service_mapping,\n    prefix='calib_share'\n)\n\nprint(\"\\nShape:\", df_transit_by_service.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_transit_by_service.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_transit_by_service)\n\n\n\n============================================================\n6. TRANSIT BY SERVICE TYPE\n============================================================\n\nShape: (25, 8)\n\nFirst few rows:\n                           HBO                 HBW                 NHB  \\\n                            OK        PK        OK        PK        OK   \ncalib_share_brt_0veh  0.093057  0.096456  0.047473  0.095224  0.153395   \ncalib_share_brt_1veh  0.089342  0.054748  0.046183  0.032496  0.148609   \ncalib_share_brt_2veh  0.048919  0.038212  0.028291  0.050144  0.219395   \ncalib_share_brt_3veh  0.069251  0.077194  0.045087  0.046860  0.183415   \ncalib_share_brt_all   0.079479  0.069215  0.042054  0.055455  0.169141   \ncalib_share_crt_0veh  0.050399  0.046084  0.062668  0.066167  0.032120   \ncalib_share_crt_1veh  0.108913  0.108609  0.131166  0.173338  0.079517   \ncalib_share_crt_2veh  0.162660  0.143757  0.185038  0.233631  0.073834   \ncalib_share_crt_3veh  0.188749  0.205590  0.257891  0.309838  0.055098   \ncalib_share_crt_all   0.107888  0.104278  0.144566  0.179742  0.055664   \n\n                                     HBC     HBSch  \n                            PK     Daily     Daily  \ncalib_share_brt_0veh  0.123222  0.270885  0.015133  \ncalib_share_brt_1veh  0.087382  0.280118  0.047447  \ncalib_share_brt_2veh  0.050852  0.191436  0.058813  \ncalib_share_brt_3veh  0.133186  0.237051  0.071987  \ncalib_share_brt_all   0.101817  0.243896  0.052479  \ncalib_share_crt_0veh  0.020874  0.077904  0.000000  \ncalib_share_crt_1veh  0.188967  0.133831  0.014499  \ncalib_share_crt_2veh  0.073795  0.193403  0.078049  \ncalib_share_crt_3veh  0.177490  0.217306  0.131698  \ncalib_share_crt_all   0.095124  0.161091  0.057136  \n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (5 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64}\n\n\n\n\nBy Access Mode: Walk vs Drive to Transit\n\n\nShow the code\n# 7. Transit by Access Type (Walk vs Drive) (within linked transit trips)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"7. TRANSIT BY ACCESS TYPE\")\nprint(\"=\" * 60)\n\naccess_mapping = {\n    'Walk': 'walkacc',\n    'Drive': 'driveacc'\n}\n\ndf_transit_by_access = calculate_categorical_shares(\n    df_obs_linked,\n    category_col='Ac_Mode2_Model',\n    weight_col='LINKED_WEIGHT',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='Linked_Mode_txt != \"MT\"',\n    category_mapping=access_mapping,\n    prefix='calib_share'\n)\n\nprint(\"\\nShape:\", df_transit_by_access.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_transit_by_access.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_transit_by_access)\n\n\n\n============================================================\n7. TRANSIT BY ACCESS TYPE\n============================================================\n\nShape: (10, 8)\n\nFirst few rows:\n                                HBO                 HBW                 NHB  \\\n                                 OK        PK        OK        PK        OK   \ncalib_share_driveacc_0veh  0.042043  0.041143  0.040632  0.044171  0.056313   \ncalib_share_driveacc_1veh  0.121467  0.141475  0.148949  0.206870  0.045113   \ncalib_share_driveacc_2veh  0.173299  0.202267  0.269593  0.365426  0.025015   \ncalib_share_driveacc_3veh  0.256207  0.246329  0.414853  0.422377  0.037477   \ncalib_share_driveacc_all   0.119140  0.129893  0.189060  0.235858  0.044757   \ncalib_share_walkacc_0veh   0.957957  0.958857  0.959368  0.955829  0.943687   \ncalib_share_walkacc_1veh   0.878533  0.858525  0.851051  0.793130  0.954887   \ncalib_share_walkacc_2veh   0.826701  0.797733  0.730407  0.634574  0.974985   \ncalib_share_walkacc_3veh   0.743793  0.753671  0.585147  0.577623  0.962523   \ncalib_share_walkacc_all    0.880860  0.870107  0.810940  0.764142  0.955243   \n\n                                          HBC     HBSch  \n                                 PK     Daily     Daily  \ncalib_share_driveacc_0veh  0.023835  0.034826  0.018714  \ncalib_share_driveacc_1veh  0.081784  0.216398  0.079303  \ncalib_share_driveacc_2veh  0.091050  0.353965  0.161519  \ncalib_share_driveacc_3veh  0.102363  0.524908  0.136143  \ncalib_share_driveacc_all   0.061683  0.300534  0.112939  \ncalib_share_walkacc_0veh   0.976165  0.965174  0.981286  \ncalib_share_walkacc_1veh   0.918216  0.783602  0.920697  \ncalib_share_walkacc_2veh   0.908950  0.646035  0.838481  \ncalib_share_walkacc_3veh   0.897637  0.475092  0.863857  \ncalib_share_walkacc_all    0.938317  0.699466  0.887061  \n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (2 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (2 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64}\n\n\n\nWalk to Transit\n\n\nShow the code\n# 8. Walk-to-Transit by Service Type (within walk-to-transit trips)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"8. WALK-TO-TRANSIT BY SERVICE TYPE\")\nprint(\"=\" * 60)\n\nwalk_service_mapping = {\n    'LCL': 'wlocal',\n    'EXP': 'wexpress',\n    'LRT': 'wlrt',\n    'CRT': 'wcrt',\n    'BRT': 'wbrt'\n}\n\ndf_walk_to_transit = calculate_categorical_shares(\n    df_obs_linked,\n    category_col='Linked_Mode_txt',\n    weight_col='LINKED_WEIGHT',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='Ac_Mode2_Model == \"Walk\" & Linked_Mode_txt != \"MT\"',\n    category_mapping=walk_service_mapping,\n    prefix='calib_share'\n)\n\n\nprint(\"\\nShape:\", df_walk_to_transit.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_walk_to_transit.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_walk_to_transit)\n\n\n\n============================================================\n8. WALK-TO-TRANSIT BY SERVICE TYPE\n============================================================\n\nShape: (25, 8)\n\nFirst few rows:\n                            HBO                 HBW                 NHB  \\\n                             OK        PK        OK        PK        OK   \ncalib_share_wbrt_0veh  0.097142  0.100595  0.049484  0.099624  0.157465   \ncalib_share_wbrt_1veh  0.101694  0.063769  0.054266  0.039404  0.155630   \ncalib_share_wbrt_2veh  0.059173  0.047900  0.038733  0.060280  0.218994   \ncalib_share_wbrt_3veh  0.089317  0.096841  0.061895  0.081126  0.190556   \ncalib_share_wbrt_all   0.089796  0.079002  0.050130  0.067799  0.173773   \ncalib_share_wcrt_0veh  0.038325  0.033586  0.058874  0.056573  0.017703   \ncalib_share_wcrt_1veh  0.050163  0.047245  0.086122  0.089959  0.064832   \ncalib_share_wcrt_2veh  0.088223  0.059357  0.095408  0.089008  0.056101   \ncalib_share_wcrt_3veh  0.048907  0.077577  0.090973  0.180144  0.024711   \ncalib_share_wcrt_all   0.052514  0.047197  0.079453  0.087829  0.038608   \n\n                                      HBC     HBSch  \n                             PK     Daily     Daily  \ncalib_share_wbrt_0veh  0.126230  0.280659  0.015421  \ncalib_share_wbrt_1veh  0.095165  0.289213  0.025199  \ncalib_share_wbrt_2veh  0.055945  0.205743  0.062380  \ncalib_share_wbrt_3veh  0.148374  0.248898  0.083332  \ncalib_share_wbrt_all   0.108510  0.259711  0.047005  \ncalib_share_wcrt_0veh  0.021384  0.052249  0.000000  \ncalib_share_wcrt_1veh  0.149215  0.053229  0.002169  \ncalib_share_wcrt_2veh  0.051479  0.075014  0.019002  \ncalib_share_wcrt_3veh  0.123171  0.094045  0.009820  \ncalib_share_wcrt_all   0.072236  0.065616  0.009058  \n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (5 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n        PK       1.0\n HBC    Daily    1.0\n HBSch  Daily    1.0\n dtype: float64}\n\n\n\n\nDrive to Transit\n\n\nShow the code\n# 9. Drive-to-Transit by Service Type (within drive-to-transit trips)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"9. DRIVE-TO-TRANSIT BY SERVICE TYPE\")\nprint(\"=\" * 60)\n\ndrive_service_mapping = {\n    'LCL': 'dlocal',\n    'EXP': 'dexpress',\n    'LRT': 'dlrt',\n    'CRT': 'dcrt',\n    'BRT': 'dbrt'\n}\n\ndf_drive_to_transit = calculate_categorical_shares(\n    df_obs_linked,\n    category_col='Linked_Mode_txt',\n    weight_col='LINKED_WEIGHT',\n    group_cols=['Veh_Cat3p', 'Purp5_text', 'PK_OK'],\n    filter_condition='Ac_Mode2_Model == \"Drive\" & Linked_Mode_txt != \"MT\"',\n    category_mapping=drive_service_mapping,\n    prefix='calib_share'\n)\n\nprint(\"\\nShape:\", df_drive_to_transit.shape)\nprint(\"\\nFirst few rows:\")\nprint(df_drive_to_transit.head(10))\nprint(\"\\nVerification:\")\nverify_shares(df_drive_to_transit)\n\n\n\n============================================================\n9. DRIVE-TO-TRANSIT BY SERVICE TYPE\n============================================================\n\nShape: (24, 8)\n\nFirst few rows:\n                            HBO                 HBW                 NHB  \\\n                             OK        PK        OK        PK        OK   \ncalib_share_dbrt_0veh  0.000000  0.000000  0.000000  0.000000  0.085185   \ncalib_share_dbrt_1veh  0.000000  0.000000  0.000000  0.006011  0.000000   \ncalib_share_dbrt_2veh  0.000000  0.000000  0.000000  0.032543  0.235044   \ncalib_share_dbrt_3veh  0.010999  0.017082  0.021379  0.000000  0.000000   \ncalib_share_dbrt_all   0.003201  0.003659  0.007410  0.015461  0.070286   \ncalib_share_dcrt_0veh  0.325511  0.337345  0.152258  0.273792  0.273724   \ncalib_share_dcrt_1veh  0.533837  0.480993  0.388536  0.493010  0.390337   \ncalib_share_dcrt_2veh  0.517750  0.476627  0.427870  0.484774  0.764956   \ncalib_share_dcrt_3veh  0.594724  0.597261  0.493327  0.487201  0.835507   \ncalib_share_dcrt_all   0.517299  0.486644  0.423858  0.477524  0.419687   \n\n                            HBC       NHB     HBSch  \n                          Daily        PK     Daily  \ncalib_share_dbrt_0veh  0.000000  0.000000  0.000000  \ncalib_share_dbrt_1veh  0.247186  0.000000  0.305749  \ncalib_share_dbrt_2veh  0.165324  0.000000  0.040294  \ncalib_share_dbrt_3veh  0.226328  0.000000  0.000000  \ncalib_share_dbrt_all   0.207087  0.000000  0.095469  \ncalib_share_dcrt_0veh  0.788925  0.000000  0.000000  \ncalib_share_dcrt_1veh  0.425698  0.635278  0.157648  \ncalib_share_dcrt_2veh  0.409480  0.296569  0.384571  \ncalib_share_dcrt_3veh  0.328868  0.653824  0.905038  \ncalib_share_dcrt_all   0.383302  0.443292  0.434748  \n\nVerification:\n=== Verifying Share Sums ===\n\nVehicle categories found: ['0veh', '1veh', '2veh', '3veh', 'all']\n\n--- Checking 0veh (4 categories) ---\n  ✅ All shares sum to 1.0 for 0veh\n\n--- Checking 1veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 1veh\n\n--- Checking 2veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 2veh\n\n--- Checking 3veh (5 categories) ---\n  ✅ All shares sum to 1.0 for 3veh\n\n--- Checking all (5 categories) ---\n  ✅ All shares sum to 1.0 for all\n\n============================================================\n✅ ALL VEHICLE CATEGORIES: Shares sum to 1.0 (within tolerance)\n\nTotal columns: 8\nTotal vehicle categories: 5\nTotal combinations: 40\n\n\n{'0veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n HBC    Daily    1.0\n NHB    PK       1.0\n HBSch  Daily    1.0\n dtype: float64,\n '1veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n HBC    Daily    1.0\n NHB    PK       1.0\n HBSch  Daily    1.0\n dtype: float64,\n '2veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n HBC    Daily    1.0\n NHB    PK       1.0\n HBSch  Daily    1.0\n dtype: float64,\n '3veh': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n HBC    Daily    1.0\n NHB    PK       1.0\n HBSch  Daily    1.0\n dtype: float64,\n 'all': HBO    OK       1.0\n        PK       1.0\n HBW    OK       1.0\n        PK       1.0\n NHB    OK       1.0\n HBC    Daily    1.0\n NHB    PK       1.0\n HBSch  Daily    1.0\n dtype: float64}"
  },
  {
    "objectID": "index.html#output-folder",
    "href": "index.html#output-folder",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "7.1 Output Folder",
    "text": "7.1 Output Folder\n\n\nShow the code\n# Create output directory if it doesn't exist\noutput_dir = Path(\"_output\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\nprint(\"=\" * 80)\nprint(\"EXPORTING CALIBRATION TARGET FILES\")\nprint(\"=\" * 80)\n\n\n================================================================================\nEXPORTING CALIBRATION TARGET FILES\n================================================================================"
  },
  {
    "objectID": "index.html#helper-functions-1",
    "href": "index.html#helper-functions-1",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "7.2 Helper Functions",
    "text": "7.2 Helper Functions\n\nExtract Values\n\n\nShow the code\ndef extract_values(df, purpose, period, pattern, include_veh_categories=True):\n    \"\"\"\n    Extract values from dataframe for given purpose/period matching a pattern.\n\n    Parameters:\n    -----------\n    df : DataFrame\n        DataFrame with MultiIndex columns (purpose, period)\n    purpose : str\n        Purpose to filter (e.g., 'HBW', 'HBO')\n    period : str\n        Period to filter (e.g., 'PK', 'OK', 'Daily')\n    pattern : str\n        Pattern to match in index (e.g., 'motor', 'bike', 'transit')\n    include_veh_categories : bool\n        If True, include all vehicle categories. If False, only include '_all' and strip suffix.\n\n    Returns:\n    --------\n    dict : {variable_name: value}\n    \"\"\"\n    results = {}\n\n    # Check if column exists\n    if (purpose, period) not in df.columns:\n        return results\n\n    # Filter rows matching pattern\n    mask = df.index.str.contains(pattern)\n\n    for idx in df[mask].index:\n        value = df.loc[idx, (purpose, period)]\n\n        if include_veh_categories:\n            # Include all vehicle categories as-is\n            results[idx] = value\n        else:\n            # Only include '_all' suffix and strip it\n            if idx.endswith('_all'):\n                # Remove '_all' suffix\n                var_name = idx.rsplit('_', 1)[0]\n                results[var_name] = value\n\n    return results\n\n\n\n\nExport Function\n\n\nShow the code\ndef export_calib_file(purpose, period, include_veh_categories=True):\n    \"\"\"\n    Export calibration target file for a given purpose and period.\n\n    Parameters:\n    -----------\n    purpose : str\n        Trip purpose (HBW, HBO, NHB, HBC, HBSch)\n    period : str\n        Time period (PK, OK, Daily)\n    include_veh_categories : bool\n        If True, include vehicle category breakdowns (_0veh, _1veh, etc.)\n        If False, only use aggregate values without vehicle suffix\n    \"\"\"\n\n    # Determine file period (Daily becomes 'pk' for HBC/HBSch)\n    file_period = 'pk' if period == 'Daily' else period.lower()\n\n    # Determine display period for header\n    display_period = file_period.capitalize()\n    # display_period = 'Pk' if period == 'PK' or period == 'Daily' else 'Ok'\n\n    filename = f\"calib_target_{purpose.lower()}_{file_period}.txt\"\n    filepath = os.path.join(output_dir, filename)\n\n    print(f\"\\nCreating {filename}... (Vehicle categories: {'Yes' if include_veh_categories else 'No'})\")\n\n    with open(filepath, 'w') as f:\n        # Write header\n        f.write(f\";Calibration target values - {purpose} {display_period}\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # Write disclaimer\n        f.write(f\";Note: Not all of the variables listed below are used directly in the Mode Choice model. Some are included solely for verification and cross-checking purposes.\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 1: Motorized vs Non-motorized (within total trips)\n        # =====================================================================\n        f.write(\";relative within total trips\\t\\t\\n\")\n\n        # Non-motorized shares only\n        nonmotorized = extract_values(df_alltrips_cat, purpose, period, 'nonmotor_', include_veh_categories)\n        if nonmotorized:\n            f.write(\"  ;nonmotorized shares \\t\\t\\n\")\n            for var, val in sorted(nonmotorized.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n\n        f.write(\"\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 2: Walk vs Bike (within nonmotorized)\n        # =====================================================================\n        f.write(\";relative within nonmotorized\\t\\t\\n\")\n\n        # Walk shares\n        walk = extract_values(df_nonmotorized_cat, purpose, period, 'walk_', include_veh_categories)\n        if walk:\n            f.write(\"  ;walk shares \\t\\t\\n\")\n            for var, val in sorted(walk.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n            f.write(\"\\t\\t\\n\")\n\n        # Bike shares\n        bike = extract_values(df_nonmotorized_cat, purpose, period, 'bike_', include_veh_categories)\n        if bike:\n            f.write(\"  ;bike shares \\t\\t\\n\")\n            for var, val in sorted(bike.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n\n        f.write(\"\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 3: Drive Alone vs Shared Ride (within auto)\n        # =====================================================================\n        f.write(\";relative within auto\\t\\t\\n\")\n\n        # Drive alone shares\n        alone = extract_values(df_auto_riders, purpose, period, 'alone_', include_veh_categories)\n        if alone:\n            f.write(\"  ;drive alone shares \\t\\t\\n\")\n            for var, val in sorted(alone.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n            f.write(\"\\t\\t\\n\")\n\n        # Shared ride shares\n        shared = extract_values(df_auto_riders, purpose, period, 'shared_', include_veh_categories)\n        if shared:\n            f.write(\"  ;shared ride shares \\t\\t\\n\")\n            for var, val in sorted(shared.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n\n        f.write(\"\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 4: SR2 vs SR3 (within shared ride)\n        # =====================================================================\n        f.write(\";relative within shared ride\\t\\t\\n\")\n\n        # SR2 shares\n        sr2 = extract_values(df_shared_by_person, purpose, period, 'sr2_', include_veh_categories)\n        if sr2:\n            f.write(\"  ;sr2 shares \\t\\t\\n\")\n            for var, val in sorted(sr2.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n            f.write(\"\\t\\t\\n\")\n\n        # SR3 shares\n        sr3 = extract_values(df_shared_by_person, purpose, period, 'sr3_', include_veh_categories)\n        if sr3:\n            f.write(\"  ;sr3 shares \\t\\t\\n\")\n            for var, val in sorted(sr3.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n\n        f.write(\"\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 5: Auto vs Transit (within motorized)\n        # =====================================================================\n        f.write(\";relative within motorized\\t\\t\\n\")\n\n        # Auto shares\n        auto = extract_values(df_motorized_cat, purpose, period, 'auto_', include_veh_categories)\n        if auto:\n            f.write(\"  ;auto shares \\t\\t\\n\")\n            for var, val in sorted(auto.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n            f.write(\"\\t\\t\\n\")\n\n        # Transit shares\n        transit = extract_values(df_motorized_cat, purpose, period, 'transit_', include_veh_categories)\n        if transit:\n            f.write(\"  ;transit shares \\t\\t\\n\")\n            for var, val in sorted(transit.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n            f.write(\" \\t\\t\\n\")\n\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 6: Transit by Service Type (within transit)\n        # =====================================================================\n        f.write(\";relative within transit\\t\\t\\n\")\n\n        # Get all transit service types\n        service_types = ['local', 'core', 'brt', 'lrt', 'express', 'crt']\n        transit_services = {}\n        for service in service_types:\n            vals = extract_values(df_transit_by_service, purpose, period, f'{service}_', include_veh_categories)\n            transit_services.update(vals)\n\n        if transit_services:\n            for var, val in sorted(transit_services.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n            f.write(\"  \\t\\t\\n\")\n\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 7: Walk vs Drive Access (within transit)\n        # =====================================================================\n        f.write(\";relative within transit\\t\\t\\n\")\n\n        # Walk access shares\n        walkacc = extract_values(df_transit_by_access, purpose, period, 'walkacc_', include_veh_categories)\n        if walkacc:\n            f.write(\"  ;walk-to-transit shares \\t\\t\\n\")\n            for var, val in sorted(walkacc.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n            f.write(\"\\t\\t\\n\")\n\n        # Drive access shares\n        driveacc = extract_values(df_transit_by_access, purpose, period, 'driveacc_', include_veh_categories)\n        if driveacc:\n            f.write(\"  ;drive-to-transit shares \\t\\t\\n\")\n            for var, val in sorted(driveacc.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n\n        f.write(\"\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 8: Walk-to-Transit by Service (within walkacc)\n        # =====================================================================\n        f.write(\";relative within walkacc\\t\\t\\n\")\n\n        # Get all walk-to-transit service types\n        walk_services = {}\n        for service in ['wlocal', 'wcore', 'wbrt', 'wlrt', 'wexpress', 'wcrt']:\n            vals = extract_values(df_walk_to_transit, purpose, period, f'{service}_', include_veh_categories)\n            walk_services.update(vals)\n\n        if walk_services:\n            for var, val in sorted(walk_services.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n\n        f.write(\"\\t\\t\\n\")\n        f.write(\"\\t\\t\\n\")\n\n        # =====================================================================\n        # SECTION 9: Drive-to-Transit by Service (within driveacc)\n        # =====================================================================\n        f.write(\";relative within driveacc\\t\\t\\n\")\n\n        # Get all drive-to-transit service types\n        drive_services = {}\n        for service in ['dlocal', 'dcore', 'dbrt', 'dlrt', 'dexpress', 'dcrt']:\n            vals = extract_values(df_drive_to_transit, purpose, period, f'{service}_', include_veh_categories)\n            drive_services.update(vals)\n\n        if drive_services:\n            for var, val in sorted(drive_services.items()):\n                f.write(f\"  {var:&lt;30}\\t=\\t{val:.4f}\\n\")\n\n    print(f\"  ✅ Written to {filepath}\")"
  },
  {
    "objectID": "index.html#export-all-files",
    "href": "index.html#export-all-files",
    "title": "Calculating the Mode Choice Calibration Parameters",
    "section": "7.3 Export All Files",
    "text": "7.3 Export All Files\n\n\nShow the code\n# Define purposes and their configuration\nexport_config = {\n    'HBW':   {'periods': ['PK', 'OK'], 'include_veh': True},\n    'HBO':   {'periods': ['PK', 'OK'], 'include_veh': True},\n    'NHB':   {'periods': ['PK', 'OK'], 'include_veh': True}, # False\n    'HBC':   {'periods': ['Daily'],    'include_veh': True}, # False\n    'HBSch': {'periods': ['Daily'],    'include_veh': True}  # False\n}\n\nfor purpose, config in export_config.items():\n    for period in config['periods']:\n        export_calib_file(purpose, period, include_veh_categories=config['include_veh'])\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"✅ EXPORT COMPLETE!\")\nprint(\"=\" * 80)\n\n\n\nCreating calib_target_hbw_pk.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_hbw_pk.txt\n\nCreating calib_target_hbw_ok.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_hbw_ok.txt\n\nCreating calib_target_hbo_pk.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_hbo_pk.txt\n\nCreating calib_target_hbo_ok.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_hbo_ok.txt\n\nCreating calib_target_nhb_pk.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_nhb_pk.txt\n\nCreating calib_target_nhb_ok.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_nhb_ok.txt\n\nCreating calib_target_hbc_pk.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_hbc_pk.txt\n\nCreating calib_target_hbsch_pk.txt... (Vehicle categories: Yes)\n  ✅ Written to _output\\calib_target_hbsch_pk.txt\n\n================================================================================\n✅ EXPORT COMPLETE!\n================================================================================"
  }
]